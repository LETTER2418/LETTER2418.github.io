<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>聚类模型</title>
      <link href="/posts/5.html"/>
      <url>/posts/5.html</url>
      
        <content type="html"><![CDATA[<h1 id="聚类模型"><a href="#聚类模型" class="headerlink" title="聚类模型"></a>聚类模型</h1><h2 id="K-means-聚类"><a href="#K-means-聚类" class="headerlink" title="K-means 聚类"></a>K-means 聚类</h2><blockquote><p>K-Means聚类是一种常用的无监督学习算法，用于将数据集划分为K个簇（cluster）。其目标是将相似的数据点分配到同一个簇中，同时使不同簇之间的数据点尽可能不同。</p><p>基本步骤</p><ul><li><p>初始化</p><p>选择K个初始聚类中心（centroid），可以随机选择数据集中的K个点，或通过其他方法初始化。</p></li><li><p>分配数据点</p><p>对于每个数据点，计算其与K个聚类中心的距离（通常使用欧氏距离），并将其分配到距离最近的聚类中心所属的簇。</p></li><li><p>更新聚类中心</p><p>对于每个簇，重新计算其聚类中心，通常取该簇中所有数据点的均值。</p></li><li><p>迭代</p><p>重复步骤2和步骤3，直到聚类中心不再发生显著变化，或达到预定的迭代次数。</p></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个包含两个子图的画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))  <span class="comment"># 设置画布大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图 1：原始数据</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># 1 行 2 列，第 1 个子图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], s=<span class="number">50</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Original Data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 K 值</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 KMeans 实例</span></span><br><span class="line">kmeans = KMeans(n_clusters=k)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合模型</span></span><br><span class="line">kmeans.fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取聚类结果</span></span><br><span class="line">labels = kmeans.predict(X)</span><br><span class="line">centroids = kmeans.cluster_centers_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图 2：聚类结果</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)  <span class="comment"># 1 行 2 列，第 2 个子图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制聚类中心</span></span><br><span class="line">plt.scatter(centroids[:, <span class="number">0</span>], centroids[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>, marker=<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;K-means Clustering&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()  <span class="comment"># 自动调整子图间距</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="层次聚类-Hierarchical-Clustering"><a href="#层次聚类-Hierarchical-Clustering" class="headerlink" title="层次聚类 (Hierarchical Clustering)"></a>层次聚类 (Hierarchical Clustering)</h2><blockquote><p>层次聚类是一种无监督学习方法，它不需要预先指定聚类的数量，而是生成一个由层次嵌套的聚类树（称为树状图或树形图）来表示数据的聚类结构。层次聚类主要有两种方式：凝聚型（Agglomerative）和分裂型（Divisive）。</p><ul><li><p>凝聚型层次聚类（Agglomerative Hierarchical Clustering）</p><ul><li>初始化：将每个数据点视为一个单独的聚类。</li><li>合并：计算每对聚类之间的距离，并合并距离最近的两个聚类。</li><li>重复：重复合并步骤，直到所有数据点都合并成一个大的聚类，或者达到某个特定的停止条件。</li><li>树状图：通过树状图展示聚类过程，树状图的每个节点代表一个聚类，节点的高度代表合并时的距离。</li></ul></li><li><p>分裂型层次聚类（Divisive Hierarchical Clustering）</p><ul><li>初始化：将所有数据点作为一个大的聚类开始。</li><li>分裂：选择一个聚类并将其分裂成两个子聚类。</li><li>重复：对每个子聚类重复分裂步骤，直到每个聚类只包含一个数据点，或者达到某个特定的停止条件。</li><li>树状图：通过树状图展示聚类过程，树状图的根节点代表初始的大聚类。</li></ul></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> dendrogram, linkage</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> AgglomerativeClustering</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">X, _ = make_blobs(n_samples=<span class="number">50</span>, centers=<span class="number">3</span>, cluster_std=<span class="number">1.0</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Scipy的linkage函数进行层次聚类</span></span><br><span class="line">linked = linkage(X, method=<span class="string">&#x27;ward&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制树状图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">dendrogram(linked, orientation=<span class="string">&#x27;top&#x27;</span>, distance_sort=<span class="string">&#x27;descending&#x27;</span>, show_leaf_counts=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Hierarchical Clustering Dendrogram&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Sample index&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Distance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Scikit-learn的AgglomerativeClustering进行层次聚类</span></span><br><span class="line">cluster = AgglomerativeClustering(n_clusters=<span class="number">3</span>, affinity=<span class="string">&#x27;euclidean&#x27;</span>, linkage=<span class="string">&#x27;ward&#x27;</span>)</span><br><span class="line">cluster.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制聚类结果</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=cluster.labels_, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Agglomerative Clustering&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="DBSCAN-聚类-Density-Based-Spatial-Clustering-of-Applications-with-Noise"><a href="#DBSCAN-聚类-Density-Based-Spatial-Clustering-of-Applications-with-Noise" class="headerlink" title="DBSCAN  聚类 (Density-Based Spatial Clustering of Applications with Noise)"></a>DBSCAN  聚类 (Density-Based Spatial Clustering of Applications with Noise)</h2><blockquote><p>DBSCAN是一种基于密度的聚类算法，它能够识别出任意形状的簇，并且能够将噪声点识别出来。DBSCAN算法的主要思想是，如果一个区域内的密度（即点的数量）足够高，则该区域中的点可以被归为一个簇。DBSCAN算法不需要事先指定簇的数量，因此它在处理复杂形状和大小的簇时非常有用。</p><p>基本步骤</p><ul><li><p>初始化</p><ul><li>选择参数 <code>ε</code>（邻域半径）和 <code>min_samples</code>（最小点数）。</li><li>将所有点标记为未访问。</li></ul></li><li><p>遍历数据点</p><ul><li>对于每个未访问的点 p，检查其ε-邻域内的点数。</li><li>如果 p 是核心点，则创建一个新的簇，并将 p 及其密度可达的所有点加入该簇。</li><li>如果 p 是边界点或噪声点，则标记为噪声。</li></ul></li><li><p>重复</p><ul><li>重复上述过程，直到所有点都被访问。</li></ul></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据（月牙形数据集）</span></span><br><span class="line">X, _ = make_moons(n_samples=<span class="number">300</span>, noise=<span class="number">0.05</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 DBSCAN 对象</span></span><br><span class="line">dbscan = DBSCAN(eps=<span class="number">0.3</span>, min_samples=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行聚类</span></span><br><span class="line">labels = dbscan.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出聚类结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cluster Labels:&quot;</span>, labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化聚类结果</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制每个簇的点</span></span><br><span class="line">unique_labels = <span class="built_in">set</span>(labels)</span><br><span class="line">colors = [plt.cm.Spectral(each) <span class="keyword">for</span> each <span class="keyword">in</span> np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">len</span>(unique_labels))]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label, color <span class="keyword">in</span> <span class="built_in">zip</span>(unique_labels, colors):</span><br><span class="line">    <span class="keyword">if</span> label == -<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 噪声点用黑色表示</span></span><br><span class="line">        color = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">        cluster_name = <span class="string">&quot;Noise&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cluster_name = <span class="string">f&quot;Cluster <span class="subst">&#123;label&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制属于当前簇的点</span></span><br><span class="line">    class_member_mask = (labels == label)</span><br><span class="line">    xy = X[class_member_mask]</span><br><span class="line">    plt.scatter(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], color=color, label=cluster_name, s=<span class="number">50</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;DBSCAN Clustering&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数模 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>评价模型</title>
      <link href="/posts/2.html"/>
      <url>/posts/2.html</url>
      
        <content type="html"><![CDATA[<h1 id="评价模型"><a href="#评价模型" class="headerlink" title="评价模型"></a>评价模型</h1><h2 id="层次分析法（AHP）"><a href="#层次分析法（AHP）" class="headerlink" title="层次分析法（AHP）"></a>层次分析法（AHP）</h2><blockquote><p>层次分析法是一种将与决策有关的元素分解成目标、准则、方案等多个层次，并在此基础上进行定性和定量分析的决策方法。</p><p>基本步骤</p><ul><li><p>建立层次结构模型</p><p>将决策问题分解为目标、准则（或标准）和方案（或备选方案）等层次。</p></li><li><p>构造判断矩阵</p><p>通过两两比较，确定各层次因素之间的相对重要性。</p></li><li><p>计算权重</p><p>通过数学方法（算数平均法、几何平均法和特征值法）计算各因素的权重。</p></li><li><p>一致性检验</p><p>检查判断矩阵的一致性，确保决策者的判断逻辑合理。</p></li><li><p>综合决策</p><p>根据权重和层次结构，计算各备选方案的总得分，从而做出决策。</p></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_weights</span>(<span class="params">matrix</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算判断矩阵的权重。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算几何平均</span></span><br><span class="line">    geometric_mean = np.prod(matrix, axis=<span class="number">1</span>) ** (<span class="number">1</span> / matrix.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 归一化得到权重</span></span><br><span class="line">    weights = geometric_mean / np.<span class="built_in">sum</span>(geometric_mean)</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_consistency</span>(<span class="params">matrix, weights</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    检查判断矩阵的一致性。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    n = matrix.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 计算加权和</span></span><br><span class="line">    weighted_sum = np.dot(matrix, weights)</span><br><span class="line">    <span class="comment"># 计算 lambda_max</span></span><br><span class="line">    lambda_max = np.mean(weighted_sum / weights)</span><br><span class="line">    <span class="comment"># 计算一致性指标 (CI)</span></span><br><span class="line">    CI = (lambda_max - n) / (n - <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 随机一致性指标 (RI)，根据 n 的值查表</span></span><br><span class="line">    RI = &#123;<span class="number">1</span>: <span class="number">0</span>, <span class="number">2</span>: <span class="number">0</span>, <span class="number">3</span>: <span class="number">0.58</span>, <span class="number">4</span>: <span class="number">0.90</span>, <span class="number">5</span>: <span class="number">1.12</span>, <span class="number">6</span>: <span class="number">1.24</span>, <span class="number">7</span>: <span class="number">1.32</span>, <span class="number">8</span>: <span class="number">1.41</span>, <span class="number">9</span>: <span class="number">1.45</span>, <span class="number">10</span>: <span class="number">1.49</span>&#125;</span><br><span class="line">    <span class="comment"># 计算一致性比率 (CR)</span></span><br><span class="line">    CR = CI / RI[n]</span><br><span class="line">    <span class="keyword">return</span> CR</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义准则判断矩阵</span></span><br><span class="line">criteria_matrix = np.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>],  <span class="comment"># 价格 vs 质量 vs 交货时间</span></span><br><span class="line">    [<span class="number">1</span>/<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>],  <span class="comment"># 质量 vs 价格 vs 交货时间</span></span><br><span class="line">    [<span class="number">1</span>/<span class="number">5</span>, <span class="number">1</span>/<span class="number">2</span>, <span class="number">1</span>]  <span class="comment"># 交货时间 vs 价格 vs 质量</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准则权重</span></span><br><span class="line">criteria_weights = calculate_weights(criteria_matrix)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准则权重:&quot;</span>, criteria_weights)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查准则判断矩阵的一致性</span></span><br><span class="line">CR = check_consistency(criteria_matrix, criteria_weights)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准则一致性比率 (CR):&quot;</span>, CR)</span><br><span class="line"><span class="keyword">if</span> CR &lt; <span class="number">0.1</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准则判断矩阵一致性可接受。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准则判断矩阵一致性不可接受，需要调整。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义各准则下的供应商判断矩阵</span></span><br><span class="line">price_matrix = np.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>],  <span class="comment"># A vs B vs C</span></span><br><span class="line">    [<span class="number">1</span>/<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>],  <span class="comment"># B vs A vs C</span></span><br><span class="line">    [<span class="number">1</span>/<span class="number">4</span>, <span class="number">1</span>/<span class="number">3</span>, <span class="number">1</span>]  <span class="comment"># C vs A vs B</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">quality_matrix = np.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">1</span>/<span class="number">3</span>, <span class="number">1</span>/<span class="number">5</span>],  <span class="comment"># A vs B vs C</span></span><br><span class="line">    [<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>/<span class="number">2</span>],  <span class="comment"># B vs A vs C</span></span><br><span class="line">    [<span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]  <span class="comment"># C vs A vs B</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">delivery_matrix = np.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">5</span>, <span class="number">3</span>],  <span class="comment"># A vs B vs C</span></span><br><span class="line">    [<span class="number">1</span>/<span class="number">5</span>, <span class="number">1</span>, <span class="number">1</span>/<span class="number">2</span>],  <span class="comment"># B vs A vs C</span></span><br><span class="line">    [<span class="number">1</span>/<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]  <span class="comment"># C vs A vs B</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算各准则下的供应商权重</span></span><br><span class="line">price_weights = calculate_weights(price_matrix)</span><br><span class="line">quality_weights = calculate_weights(quality_matrix)</span><br><span class="line">delivery_weights = calculate_weights(delivery_matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;价格权重:&quot;</span>, price_weights)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;质量权重:&quot;</span>, quality_weights)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交货时间权重:&quot;</span>, delivery_weights)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查各准则判断矩阵的一致性</span></span><br><span class="line">CR_price = check_consistency(price_matrix, price_weights)</span><br><span class="line">CR_quality = check_consistency(quality_matrix, quality_weights)</span><br><span class="line">CR_delivery = check_consistency(delivery_matrix, delivery_weights)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;价格判断矩阵一致性比率 (CR):&quot;</span>, CR_price)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;质量判断矩阵一致性比率 (CR):&quot;</span>, CR_quality)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交货时间判断矩阵一致性比率 (CR):&quot;</span>, CR_delivery)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 综合得分</span></span><br><span class="line">supplier_scores = np.array([</span><br><span class="line">    np.<span class="built_in">sum</span>(price_weights * criteria_weights[<span class="number">0</span>]),</span><br><span class="line">    np.<span class="built_in">sum</span>(quality_weights * criteria_weights[<span class="number">1</span>]),</span><br><span class="line">    np.<span class="built_in">sum</span>(delivery_weights * criteria_weights[<span class="number">2</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最终得分</span></span><br><span class="line">supplier_names = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> name, score <span class="keyword">in</span> <span class="built_in">zip</span>(supplier_names, supplier_scores):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;供应商 <span class="subst">&#123;name&#125;</span> 的综合得分: <span class="subst">&#123;score:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择最佳供应商</span></span><br><span class="line">best_supplier = supplier_names[np.argmax(supplier_scores)]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最佳供应商是: <span class="subst">&#123;best_supplier&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="主成分分析评价法-PCA"><a href="#主成分分析评价法-PCA" class="headerlink" title="主成分分析评价法(PCA)"></a>主成分分析评价法(PCA)</h2><blockquote><p>主成分分析评价法是将多个变量通过线性变换以选出较少个数重要变量的一种多元统计分析方法。</p><p>主成分保留了原始变量绝大多数信息。各个主成分之间互不相关。每个主成分都是原始变量的线性组合。</p><p>根据权重和层次结构，计算各备选方案的总得分，从而做出决策。</p><p>基本步骤</p><ul><li><p>无量纲化</p><ul><li><strong>归一化</strong>：min-max归一化，平均归一化 </li><li><strong>标准化</strong>：均值为0，协方差为1</li></ul></li><li><p>计算协方差矩阵</p></li><li><p>计算协方差矩阵的特征值和特征向量</p></li><li><p>选择主成分</p><p>根据特征值的大小，选择前 k 个最大的特征值对应的特征向量，作为主成分</p></li><li><p>构建投影矩阵</p><p>将选择的 k 个特征向量组成投影矩阵</p></li><li><p>数据降维</p><p>将原始数据 X 投影到主成分空间，得到降维后的数据 </p></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_standardized = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行 PCA</span></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)  <span class="comment"># 选择降维后的维度</span></span><br><span class="line">X_pca = pca.fit_transform(X_standardized)</span><br><span class="line"><span class="comment"># X_standardized 是原始数据，形状为 (n_samples, n_features)。</span></span><br><span class="line"><span class="comment"># X_pca 是降维后的数据，形状为 (n_samples, n_components)。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;降维后的数据：\n&quot;</span>, X_pca)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;解释方差比例：&quot;</span>, pca.explained_variance_ratio_)</span><br></pre></td></tr></table></figure><h2 id="模糊综合评价法"><a href="#模糊综合评价法" class="headerlink" title="模糊综合评价法"></a>模糊综合评价法</h2><blockquote><p>模糊综合评价法是一种基于模糊数学的综合评价方法，用于处理具有模糊性和不确定性的问题。它通过将定性指标转化为定量评价，适用于多因素、多层次的复杂系统评价。</p><p>基本步骤</p><ul><li>确定评价因素集<br>明确影响评价对象的各个因素，记为 U。</li><li>确定评语集<br>设定评价等级，记为 V。</li><li>确定权重集<br>为各因素分配权重，反映其重要性，记为W，且权重和为1。</li><li>构建模糊关系矩阵<br>通过专家打分或数据分析，确定每个因素对评语集的隶属度，形成模糊关系矩阵 R。</li><li>进行模糊合成运算<br>将权重集 W与模糊关系矩阵 R合成，得到模糊评价结果 B=W∘R。</li><li>得出综合评价结果<br>对 B 进行去模糊化处理，得到最终评价结果。</li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fuzzy_comprehensive_evaluation</span>(<span class="params">weights, fuzzy_relation_matrix, scores</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    模糊综合评价法</span></span><br><span class="line"><span class="string">    :param weights: 权重集，格式为 numpy 数组，例如 np.array([0.3, 0.5, 0.2])</span></span><br><span class="line"><span class="string">    :param fuzzy_relation_matrix: 模糊关系矩阵，格式为 numpy 二维数组</span></span><br><span class="line"><span class="string">    :param scores: 每个评语对应的分数，格式为 numpy 数组，例如 np.array([5, 4, 3, 2, 1])</span></span><br><span class="line"><span class="string">    :return: 模糊评价结果（隶属度）和系统总得分</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 检查权重和模糊关系矩阵的维度是否匹配</span></span><br><span class="line">    <span class="comment"># 在 NumPy 中，一维数组的形状表示为 (n,)，其中 n 是数组的长度</span></span><br><span class="line">    <span class="keyword">if</span> weights.shape[<span class="number">0</span>] != fuzzy_relation_matrix.shape[<span class="number">0</span>]:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;权重集和模糊关系矩阵的维度不匹配！&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模糊合成运算（使用加权平均法）</span></span><br><span class="line">    evaluation_result = np.dot(weights, fuzzy_relation_matrix)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 归一化处理（确保评价结果的总和为1）</span></span><br><span class="line">    evaluation_result = evaluation_result / np.<span class="built_in">sum</span>(evaluation_result)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算系统总得分</span></span><br><span class="line">    total_score = np.dot(evaluation_result, scores)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> evaluation_result, total_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 权重集：外观、性能、价格的权重分别为 0.3, 0.5, 0.2</span></span><br><span class="line">    weights = np.array([<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模糊关系矩阵：每一行对应一个因素，每一列对应一个评语</span></span><br><span class="line">    <span class="comment"># 例如，外观的模糊关系为 [0.6, 0.3, 0.1, 0.0, 0.0]</span></span><br><span class="line">    fuzzy_relation_matrix = np.array([</span><br><span class="line">        [<span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],  <span class="comment"># 外观</span></span><br><span class="line">        [<span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.2</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],  <span class="comment"># 性能</span></span><br><span class="line">        [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.0</span>]   <span class="comment"># 价格</span></span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每个评语对应的分数：好=5分，较好=4分，一般=3分，较差=2分，差=1分</span></span><br><span class="line">    scores = np.array([<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行模糊综合评价</span></span><br><span class="line">    result, total_score = fuzzy_comprehensive_evaluation(weights, fuzzy_relation_matrix, scores)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模糊综合评价结果（隶属度）：&quot;</span>, result)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;系统总得分：&quot;</span>, total_score)</span><br></pre></td></tr></table></figure><h2 id="灰色综合评价法"><a href="#灰色综合评价法" class="headerlink" title="灰色综合评价法"></a>灰色综合评价法</h2><blockquote><p>灰色综合评价法是一种基于灰色系统理论的评价方法，适用于信息不完全或数据量较少的系统。通过灰色关联分析来确定各因素之间的关联度，从而进行综合评价。</p><p>基本步骤</p><ul><li><p>确定评价指标和样本数据</p></li><li><p>无量纲化</p><p>不推荐使用标准化 </p></li><li><p>确定参考序列  </p></li><li><p>计算灰色关联系数</p></li><li><p>计算灰色关联度</p></li><li><p>综合评价</p></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">grey_relation_analysis</span>(<span class="params">data, reference_index=<span class="number">0</span>, rho=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    灰色关联度分析</span></span><br><span class="line"><span class="string">    :param data: 数据矩阵，形状为 (n, m)，n 为评价对象数，m 为评价指标数</span></span><br><span class="line"><span class="string">    :param reference_index: 参考序列的索引，默认为 0</span></span><br><span class="line"><span class="string">    :param rho: 分辨系数，默认为 0.5</span></span><br><span class="line"><span class="string">    :return: 灰色关联系数矩阵，形状为 (n, m)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 数据标准化处理（极差标准化）</span></span><br><span class="line">    normalized_data = (data - np.<span class="built_in">min</span>(data, axis=<span class="number">0</span>)) / (np.<span class="built_in">max</span>(data, axis=<span class="number">0</span>) - np.<span class="built_in">min</span>(data, axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 确定参考序列</span></span><br><span class="line">    reference_sequence = normalized_data[reference_index]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算差值矩阵</span></span><br><span class="line">    diff = np.<span class="built_in">abs</span>(normalized_data - reference_sequence)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算灰色关联系数</span></span><br><span class="line">    min_diff = np.<span class="built_in">min</span>(diff)</span><br><span class="line">    max_diff = np.<span class="built_in">max</span>(diff)</span><br><span class="line">    grey_relation_coefficients = (min_diff + rho * max_diff) / (diff + rho * max_diff)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> grey_relation_coefficients</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_weights_grey_mean</span>(<span class="params">grey_relation_coefficients</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算指标权重（基于灰色关联度均值法，或可采用熵权法）</span></span><br><span class="line"><span class="string">    :param grey_relation_coefficients: 灰色关联系数矩阵，形状为 (n, m)</span></span><br><span class="line"><span class="string">    :return: 权重向量，形状为 (m,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算每个指标的灰色关联度均值</span></span><br><span class="line">    mean_grey_relation = np.mean(grey_relation_coefficients, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算权重</span></span><br><span class="line">    weights = mean_grey_relation / np.<span class="built_in">sum</span>(mean_grey_relation)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_scores</span>(<span class="params">grey_relation_coefficients, weights</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算子序列综合得分</span></span><br><span class="line"><span class="string">    :param grey_relation_coefficients: 灰色关联系数矩阵，形状为 (n, m)</span></span><br><span class="line"><span class="string">    :param weights: 权重向量，形状为 (m,)</span></span><br><span class="line"><span class="string">    :return: 综合得分向量，形状为 (n,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算综合得分</span></span><br><span class="line">    scores = np.dot(grey_relation_coefficients, weights)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 数据矩阵：4 个评价对象，3 个评价指标</span></span><br><span class="line">    data = np.array([</span><br><span class="line">        [<span class="number">80</span>, <span class="number">90</span>, <span class="number">70</span>],</span><br><span class="line">        [<span class="number">85</span>, <span class="number">88</span>, <span class="number">75</span>],</span><br><span class="line">        [<span class="number">78</span>, <span class="number">92</span>, <span class="number">72</span>],</span><br><span class="line">        [<span class="number">82</span>, <span class="number">89</span>, <span class="number">74</span>]</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行灰色关联度分析</span></span><br><span class="line">    grey_relation_coefficients = grey_relation_analysis(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算指标权重</span></span><br><span class="line">    weights = calculate_weights_grey_mean(grey_relation_coefficients)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算子序列综合得分</span></span><br><span class="line">    scores = calculate_scores(grey_relation_coefficients, weights)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;灰色关联系数矩阵：\n&quot;</span>, grey_relation_coefficients)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;指标权重：&quot;</span>, weights)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;子序列综合得分：&quot;</span>, scores)</span><br></pre></td></tr></table></figure><h2 id="熵权法"><a href="#熵权法" class="headerlink" title="熵权法"></a>熵权法</h2><blockquote><p>熵权法是一种基于信息熵的客观赋权方法，用于确定各指标在综合评价中的权重。其核心思想是：指标的数据变异程度越大，提供的信息量越多，其权重也应越大。熵权法适用于多指标决策问题，能够减少主观赋权带来的偏差。</p><p>基本步骤</p><ul><li>无量纲化</li><li>计算第 i 个指标下第 j 个方案占总方案的比重</li><li>计算第 i 个指标的熵值</li><li>计算第 i 个指标的差异系数</li><li>计算第 i 个指标的权重</li><li>根据权重计算各方案的综合评价值</li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">entropy_weight</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="comment"># 数据标准化</span></span><br><span class="line">    data_normalized = (data - np.<span class="built_in">min</span>(data, axis=<span class="number">0</span>)) / (np.<span class="built_in">max</span>(data, axis=<span class="number">0</span>) - np.<span class="built_in">min</span>(data, axis=<span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算比重</span></span><br><span class="line">    p = data_normalized / np.<span class="built_in">sum</span>(data_normalized, axis=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算信息熵</span></span><br><span class="line">    k = <span class="number">1</span> / np.log(data.shape[<span class="number">0</span>])</span><br><span class="line">    e = -k * np.<span class="built_in">sum</span>(p * np.log(p + <span class="number">1e-10</span>), axis=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算差异系数</span></span><br><span class="line">    d = <span class="number">1</span> - e</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算权重</span></span><br><span class="line">    w = d / np.<span class="built_in">sum</span>(d)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> w, data_normalized</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = np.array([[<span class="number">7</span>, <span class="number">9</span>, <span class="number">6</span>],</span><br><span class="line">                 [<span class="number">8</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">                 [<span class="number">9</span>, <span class="number">6</span>, <span class="number">7</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算权重和标准化数据</span></span><br><span class="line">weights, data_normalized = entropy_weight(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算综合评价值</span></span><br><span class="line">scores = np.dot(data_normalized ,weights)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;权重:&quot;</span>, weights)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;综合评价值:&quot;</span>, scores)</span><br></pre></td></tr></table></figure><h2 id="BP神经网络评价法"><a href="#BP神经网络评价法" class="headerlink" title="BP神经网络评价法"></a>BP神经网络评价法</h2><blockquote><p>BP神经网络评价法是一种基于反向传播（Back Propagation, BP）神经网络的多指标综合评价方法。BP神经网络是一种多层前馈神经网络，通过反向传播算法调整网络参数，能够拟合复杂的非线性关系，适用于解决多指标、非线性的综合评价问题。</p><p>基本步骤</p><ul><li><p>确定评价指标和样本数据</p></li><li><p>无量纲化</p></li><li><p>构建神经网络模型</p><p>确定网络结构（如层数、每层的神经元数量）。</p><p>选择激活函数（如 Sigmoid、ReLU）和损失函数（如均方误差）。</p><p>初始化权重和偏置。 </p></li><li><p>训练模型</p><p>使用训练集数据，通过反向传播算法调整权重和偏置，最小化损失函数。</p><p>设置训练参数（如学习率、迭代次数）。</p></li><li><p>模型验证</p><p>使用测试集数据验证模型的性能，评估预测精度。</p></li><li><p>综合评价</p><p>将待评价方案的指标数据输入训练好的模型，得到综合评价值。</p></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = np.array([[<span class="number">7</span>, <span class="number">9</span>, <span class="number">6</span>],</span><br><span class="line">                 [<span class="number">8</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">                 [<span class="number">9</span>, <span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">                 [<span class="number">6</span>, <span class="number">8</span>, <span class="number">7</span>],</span><br><span class="line">                 [<span class="number">7</span>, <span class="number">7</span>, <span class="number">9</span>]])</span><br><span class="line">target = np.array([<span class="number">0.8</span>, <span class="number">0.7</span>, <span class="number">0.6</span>, <span class="number">0.75</span>, <span class="number">0.85</span>])  <span class="comment"># 综合评价值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">data_scaled = scaler.fit_transform(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data_scaled, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建神经网络模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">10</span>, input_dim=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>))  <span class="comment"># 隐藏层</span></span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;linear&#x27;</span>))  <span class="comment"># 输出层</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train, epochs=<span class="number">100</span>, batch_size=<span class="number">2</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型验证</span></span><br><span class="line">loss = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集损失:&quot;</span>, loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 综合评价</span></span><br><span class="line">new_data = np.array([[<span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>]])</span><br><span class="line">new_data_scaled = scaler.transform(new_data)</span><br><span class="line">predicted_score = model.predict(new_data_scaled)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测综合评价值:&quot;</span>, predicted_score)</span><br></pre></td></tr></table></figure><h2 id="数据包络分析法（DEA"><a href="#数据包络分析法（DEA" class="headerlink" title="数据包络分析法（DEA)"></a>数据包络分析法（DEA)</h2><blockquote><p>数据包络分析法是一种用于评估决策单元（Decision Making Units，DMUs）相对效率的非参数方法。它通过构建数学规划模型，比较具有相同输入和输出的DMUs的效率，从而识别出相对高效和低效的单位。</p><p>DEA主要有两种常用的模型：</p><p><strong>CCR模型</strong>(CRS)</p><ul><li>假设规模收益不变，即生产规模的扩大不会改变效率。</li><li>适用于评估在规模不变情况下的效率。</li></ul><p><strong>BCC模型</strong>(VRS)</p><ul><li>允许规模收益可变，即考虑规模经济或规模不经济的影响。</li><li>适用于评估在规模可变情况下的效率。</li></ul><p>基本步骤</p><ul><li><p>确定输入和输出指标</p></li><li><p>构建DEA模型</p><p>根据选择的模型（CCR或BCC），构建相应的线性规划模型。</p><p>模型的目标是最大化每个DMU的效率评分，同时确保其他DMUs的效率不超过1。</p></li><li><p>求解模型</p><p>使用线性规划求解器求解模型，得到每个DMU的效率评分。</p></li><li><p>分析结果</p><p>效率评分等于1的DMU被认为是在生产前沿面上，即相对高效。</p><p>效率评分小于1的DMU被认为是低效的，需要进行改进。</p></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skdeapackage <span class="keyword">import</span> dea</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入数据（资金, 人力）</span></span><br><span class="line">inputs = np.array([</span><br><span class="line">    [<span class="number">100</span>, <span class="number">50</span>],</span><br><span class="line">    [<span class="number">150</span>, <span class="number">70</span>],</span><br><span class="line">    [<span class="number">200</span>, <span class="number">80</span>],</span><br><span class="line">    [<span class="number">120</span>, <span class="number">60</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出数据（产量, 利润）</span></span><br><span class="line">outputs = np.array([</span><br><span class="line">    [<span class="number">80</span>, <span class="number">30</span>],</span><br><span class="line">    [<span class="number">100</span>, <span class="number">40</span>],</span><br><span class="line">    [<span class="number">120</span>, <span class="number">50</span>],</span><br><span class="line">    [<span class="number">90</span>, <span class="number">35</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义Min-Max归一化函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">min_max_normalize</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="keyword">return</span> (data - np.<span class="built_in">min</span>(data)) / (np.<span class="built_in">max</span>(data) - np.<span class="built_in">min</span>(data))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按列进行归一化</span></span><br><span class="line">inputs_normalized = np.apply_along_axis(min_max_normalize, <span class="number">0</span>, inputs)</span><br><span class="line">outputs_normalized = np.apply_along_axis(min_max_normalize, <span class="number">0</span>, outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算效率分数，选择CRS模型</span></span><br><span class="line">efficiency_scores = dea(inputs_normalized, outputs_normalized, model=<span class="string">&#x27;crs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出效率分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;效率分数:&quot;</span>, efficiency_scores)</span><br></pre></td></tr></table></figure><h2 id="优劣解距离法-TOPSIS"><a href="#优劣解距离法-TOPSIS" class="headerlink" title="优劣解距离法(TOPSIS)"></a>优劣解距离法(TOPSIS)</h2><blockquote><p>基于各方案与理想解和负理想解的距离来评价方案的优劣。距离理想解越近且距离负理想解越远的方案，被认为是最优方案。</p><p>基本步骤</p><ul><li><p>构建决策矩阵<br>将备选方案和评价指标以矩阵形式表示，其中行代表方案，列代表评价指标。</p></li><li><p>无量纲化决策矩阵</p></li><li><p>确定权重<br>根据各指标的重要性，为每个指标赋予权重。权重可以通过主观方法（如专家打分）或客观方法（如熵值法）确定。</p></li><li><p>计算加权标准化矩阵<br>将标准化后的矩阵与权重相乘，得到加权标准化矩阵。</p></li><li><p>确定理想解和负理想解</p><p>理想解：每个指标的最优值（正向指标取最大值，负向指标取最小值）。</p><p>负理想解：每个指标的最劣值（正向指标取最小值，负向指标取最大值）。</p></li><li><p>计算距离<br>计算每个方案与理想解和负理想解的欧氏距离。</p></li><li><p>计算相对接近度<br>通过公式计算每个方案与理想解的相对接近度，值越大表示方案越优。</p></li><li><p>排序和选择<br>根据相对接近度对方案进行排序，选择最优方案。</p></li></ul></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">topsis</span>(<span class="params">decision_matrix, weights, impacts</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    TOPSIS算法实现</span></span><br><span class="line"><span class="string">    :param decision_matrix: 决策矩阵，每一行代表一个方案，每一列代表一个指标</span></span><br><span class="line"><span class="string">    :param weights: 各指标的权重</span></span><br><span class="line"><span class="string">    :param impacts: 各指标的影响方向（+1表示正向指标，-1表示负向指标）</span></span><br><span class="line"><span class="string">    :return: 相对接近度及排序结果</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. 标准化决策矩阵</span></span><br><span class="line">    normalized_matrix = decision_matrix / np.sqrt((decision_matrix ** <span class="number">2</span>).<span class="built_in">sum</span>(axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 计算加权标准化矩阵</span></span><br><span class="line">    weighted_matrix = normalized_matrix * weights</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 确定理想解和负理想解</span></span><br><span class="line">    ideal_best = np.<span class="built_in">max</span>(weighted_matrix * impacts, axis=<span class="number">0</span>)</span><br><span class="line">    ideal_worst = np.<span class="built_in">min</span>(weighted_matrix * impacts, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 计算距离</span></span><br><span class="line">    distance_best = np.sqrt(((weighted_matrix - ideal_best) ** <span class="number">2</span>).<span class="built_in">sum</span>(axis=<span class="number">1</span>))</span><br><span class="line">    distance_worst = np.sqrt(((weighted_matrix - ideal_worst) ** <span class="number">2</span>).<span class="built_in">sum</span>(axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. 计算相对接近度</span></span><br><span class="line">    closeness = distance_worst / (distance_best + distance_worst)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. 排序</span></span><br><span class="line">    ranked_indices = np.argsort(closeness)[::-<span class="number">1</span>]  <span class="comment"># 从大到小排序</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> closeness, ranked_indices</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">decision_matrix = np.array([</span><br><span class="line">    [<span class="number">7</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">8</span>],  <span class="comment"># 方案1</span></span><br><span class="line">    [<span class="number">8</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">7</span>],  <span class="comment"># 方案2</span></span><br><span class="line">    [<span class="number">9</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">9</span>],  <span class="comment"># 方案3</span></span><br><span class="line">    [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">6</span>]   <span class="comment"># 方案4</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">weights = np.array([<span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.2</span>])  <span class="comment"># 各指标权重</span></span><br><span class="line">impacts = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])         <span class="comment"># 各指标影响方向（1表示正向，-1表示负向）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行TOPSIS</span></span><br><span class="line">closeness, ranked_indices = topsis(decision_matrix, weights, impacts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;相对接近度:&quot;</span>, closeness)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;方案排序:&quot;</span>, ranked_indices + <span class="number">1</span>)  <span class="comment"># 方案编号从1开始</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数模 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>预测模型</title>
      <link href="/posts/4.html"/>
      <url>/posts/4.html</url>
      
        <content type="html"><![CDATA[<h1 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h1><h2 id="神经网络预测"><a href="#神经网络预测" class="headerlink" title="神经网络预测"></a>神经网络预测</h2><blockquote><p>神经网络预测是指利用神经网络模型对未知数据进行预测或分类的过程。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">X = np.random.rand(<span class="number">1000</span>, <span class="number">10</span>)</span><br><span class="line">y = np.<span class="built_in">sum</span>(X, axis=<span class="number">1</span>) + np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据分割</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">64</span>, input_dim=<span class="number">10</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train, epochs=<span class="number">50</span>, batch_size=<span class="number">32</span>, validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估</span></span><br><span class="line">mse = np.mean((y_test - y_pred.flatten()) ** <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Squared Error: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="灰色预测"><a href="#灰色预测" class="headerlink" title="灰色预测"></a>灰色预测</h2><blockquote><p>灰色预测是一种对含有不确定因素的时间序列进行预测的方法，特别适用于数据量少且数据波动较大的情况。其基本思想是通过生成灰色序列，对原始数据进行处理，提高数据的规律性，从而建立预测模型进行预测。</p></blockquote><h2 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h2><blockquote><p>通过拟合自变量与因变量之间的线性关系来预测目标值。目标是找到一条直线，使得预测值与实际值的误差最小（通常使用最小二乘法）。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成随机数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X = np.random.rand(<span class="number">100</span>, <span class="number">1</span>) * <span class="number">10</span>  <span class="comment"># 100个样本，1个特征</span></span><br><span class="line"><span class="comment"># 创建一个线性关系，添加一些噪声</span></span><br><span class="line">y = <span class="number">3</span> * X.squeeze() + <span class="number">2</span> + np.random.randn(<span class="number">100</span>) * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归模型</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用测试集进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差: <span class="subst">&#123;mse:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算R²分数</span></span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;R²分数: <span class="subst">&#123;r2:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="时间序列预测"><a href="#时间序列预测" class="headerlink" title="时间序列预测"></a>时间序列预测</h2><blockquote><p>时间序列预测是一种基于历史数据来预测未来值的技术。</p><p>单变量时间序列预测：只依赖于一个单一的时间序列数据源。单变量预测方法包括ARIMA（自回归积分滑动平均模型），SARIMA（季节性自回归积分滑动平均模型），指数平滑法，自回归（AR）模型，移动平均（MA）模型。</p><p>多变量时间序列预测：使用两个或更多的相关时间序列来进行预测。多变量预测方法包括向量自回归（VAR）模型，状态空间模型，SARIMAX（季节性自回归积分滑动平均模型扩展），机器学习方法：如随机森林、梯度提升机（GBM）、支持向量机（SVM）等，深度学习方法：如循环神经网络（RNN）、长短期记忆网络（LSTM）。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 数模 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分类模型</title>
      <link href="/posts/3.html"/>
      <url>/posts/3.html</url>
      
        <content type="html"><![CDATA[<h1 id="分类模型"><a href="#分类模型" class="headerlink" title="分类模型"></a>分类模型</h1><blockquote><p>分类模型是数学建模中一种根据数据特征将数据集中的实例划分为不同类别或组的模型</p></blockquote><h2 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h2><blockquote><p>逻辑回归是一种广义的线性回归分析模型，属于机器学习中的监督学习。其推导过程与计算方式类似于回归的过程，但实际上主要是用来解决二分类问题（也可以解决多分类问题）。逻辑回归通过拟合数据，预测某个事件发生的概率，并根据概率值进行分类。它的核心是通过 Sigmoid 函数将线性回归的输出映射到 [0, 1] 区间，表示概率值。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集（以二分类为例）</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data[:<span class="number">100</span>, :]  <span class="comment"># 只取前两类</span></span><br><span class="line">y = data.target[:<span class="number">100</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建逻辑回归模型,默认损失函数是对数损失</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率:&quot;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分类报告:\n&quot;</span>, classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure><h2 id="决策树（Decision-Tree）"><a href="#决策树（Decision-Tree）" class="headerlink" title="决策树（Decision Tree）"></a>决策树（Decision Tree）</h2><blockquote><p>决策树是一种常用的机器学习算法，广泛应用于分类和回归任务。它通过树状结构对数据进行分割，每个内部节点表示一个特征或属性的判断条件，每个分支代表一个可能的判断结果，而每个叶子节点则代表一个类别（分类任务）或一个值（回归任务）。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, plot_tree</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载鸢尾花数据集</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data  <span class="comment"># 特征</span></span><br><span class="line">y = data.target  <span class="comment"># 标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分：训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建决策树分类器</span></span><br><span class="line">model = DecisionTreeClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们有一些无标签数据</span></span><br><span class="line">unlabeled_data = np.array([</span><br><span class="line">    [<span class="number">5.1</span>, <span class="number">3.5</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],  <span class="comment"># 样本1</span></span><br><span class="line">    [<span class="number">6.7</span>, <span class="number">3.0</span>, <span class="number">5.2</span>, <span class="number">2.3</span>],  <span class="comment"># 样本2</span></span><br><span class="line">    [<span class="number">4.9</span>, <span class="number">3.1</span>, <span class="number">1.5</span>, <span class="number">0.1</span>],  <span class="comment"># 样本3</span></span><br><span class="line">    [<span class="number">5.8</span>, <span class="number">2.7</span>, <span class="number">4.1</span>, <span class="number">1.0</span>]   <span class="comment"># 样本4</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用训练好的模型对无标签数据进行预测</span></span><br><span class="line">predicted_labels = model.predict(unlabeled_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出预测结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted Labels:&quot;</span>, predicted_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果需要类别名称，可以映射到目标名称</span></span><br><span class="line">predicted_class_names = data.target_names[predicted_labels]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted Class Names:&quot;</span>, predicted_class_names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化决策树</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plot_tree(model, filled=<span class="literal">True</span>, feature_names=data.feature_names, class_names=data.target_names)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="随机森林（Random-Forest）"><a href="#随机森林（Random-Forest）" class="headerlink" title="随机森林（Random Forest）"></a>随机森林（Random Forest）</h2><blockquote><p>随机森林是一种基于集成学习的机器学习算法，广泛应用于分类和回归任务。它通过构建多个决策树并将它们的预测结果进行集成，从而提高模型的准确性和鲁棒性。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X, y = data.data, data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练随机森林模型</span></span><br><span class="line">model = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出预测结果</span></span><br><span class="line">packed_results = <span class="built_in">list</span>(<span class="built_in">zip</span>(y_test, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签&amp;预测结果&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> true_label, pred_label <span class="keyword">in</span> packed_results:</span><br><span class="line">    <span class="built_in">print</span>(true_label,pred_label)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型准确率: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="朴素贝叶斯（Naive-Bayes）"><a href="#朴素贝叶斯（Naive-Bayes）" class="headerlink" title="朴素贝叶斯（Naive Bayes）"></a>朴素贝叶斯（Naive Bayes）</h2><blockquote><p>朴素贝叶斯（Naive Bayes）是一种基于贝叶斯定理的简单概率分类算法，它的“朴素”体现在假设特征之间相互独立，尽管现实中这一假设往往不成立，但朴素贝叶斯分类器仍然能够在许多实际应用中取得不错的效果。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练朴素贝叶斯模型</span></span><br><span class="line">model = GaussianNB()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line">result = <span class="built_in">list</span>(<span class="built_in">zip</span>(y_test, y_pred))</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> result:</span><br><span class="line"> <span class="built_in">print</span>(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="K近邻算法（KNN）"><a href="#K近邻算法（KNN）" class="headerlink" title="K近邻算法（KNN）"></a>K近邻算法（KNN）</h2><blockquote><p>K近邻算法是一种监督学习算法，主要用于分类和回归任务。它的核心思想是：给定一个样本，通过查找其最近的 K 个邻居，根据这些邻居的类别或值来预测该样本的类别或值。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 KNN 模型（选择 K=3）</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;准确率: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="支持向量机（SVM）"><a href="#支持向量机（SVM）" class="headerlink" title="支持向量机（SVM）"></a>支持向量机（SVM）</h2><blockquote><p>支持向量机（Support Vector Machine, SVM） 是一种强大的监督学习算法，主要用于分类和回归任务。它的核心思想是找到一个最优的超平面，将不同类别的样本分开，并且最大化类别之间的边界（即“间隔”）。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 SVM 模型（使用 RBF 核）</span></span><br><span class="line">svm = SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>, C=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred = svm.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;准确率: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数模 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>优化模型-规划模型</title>
      <link href="/posts/1.html"/>
      <url>/posts/1.html</url>
      
        <content type="html"><![CDATA[<h1 id="优化模型-规划模型"><a href="#优化模型-规划模型" class="headerlink" title="优化模型-规划模型"></a>优化模型-规划模型</h1><h2 id="数学规划"><a href="#数学规划" class="headerlink" title="数学规划"></a>数学规划</h2><blockquote><p>数学规划（Mathematical Programming）是运筹学的一个分支，研究在给定的条件（约束条件）下，如何按照某一衡量指标（目标函数）来寻求计划、管理、工作中的最优方案。通俗来讲就是：求目标函数在一定约束条件下的极值问题。</p></blockquote><h2 id="线性规划-LP"><a href="#线性规划-LP" class="headerlink" title="线性规划(LP)"></a>线性规划(LP)</h2><blockquote><p>定义：目标函数和约束条件均是决策变量的线性表达式。</p><p>线性规划有通用求准确解的方法，它的最优解只存在于可行域的边界上。</p><p>中小规模问题：使用单纯形法。</p><p>大规模问题：使用内点法。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> optimize <span class="keyword">as</span> op</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给出变量取值范围</span></span><br><span class="line">x1 = (<span class="number">0</span>, <span class="literal">None</span>)</span><br><span class="line">x2 = (<span class="number">0</span>, <span class="literal">None</span>)</span><br><span class="line">x3 = (<span class="number">0</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">c = np.array([-<span class="number">2</span>, -<span class="number">3</span>, <span class="number">5</span>])  <span class="comment"># 目标函数系数,3x1列向量</span></span><br><span class="line"></span><br><span class="line">A_ub = np.array([[-<span class="number">2</span>, <span class="number">5</span>, -<span class="number">1</span>], [<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>]])  <span class="comment"># 不等式约束系数A，2x3维矩阵</span></span><br><span class="line">B_ub = np.array([-<span class="number">10</span>, <span class="number">12</span>])  <span class="comment"># 等式约束系数b, 2x1维列向量</span></span><br><span class="line">A_eq = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])  <span class="comment"># 等式约束系数Aeq，3x1维列向量</span></span><br><span class="line">B_eq = np.array([<span class="number">7</span>])  <span class="comment"># 等式约束系数beq，1x1数值</span></span><br><span class="line"></span><br><span class="line">res = op.linprog(c, A_ub, B_ub, A_eq, B_eq, bounds=(x1, x2, x3), method=<span class="string">&#x27;highs&#x27;</span>)  <span class="comment"># 调用函数进行求解</span></span><br><span class="line"><span class="comment">#奇怪的警告,scipy还是牢版本,不管了</span></span><br></pre></td></tr></table></figure><h2 id="非线性规划-NLP"><a href="#非线性规划-NLP" class="headerlink" title="非线性规划(NLP)"></a>非线性规划(NLP)</h2><blockquote><p>定义：目标函数或约束条件中存在非线性表达式。 </p><p>非线性规划的最优解（若存在）可能在其可行域的任一点达到，目前非线性规划还没有适合各种问题的一般解法，各种方法都有其特定的适用范围。</p><p>Scipy 工具包中的 optimize 模块可求解常见的非线性规划问题：</p><p>brent()：SciPy.optimize 模块中求解<strong>单变量无约束优化</strong>问题的首选方法，<strong>局部优化方法</strong>，混合使用牛顿法/二分法。既能保证稳定性又能快速收敛。 </p><p>fmin()：SciPy.optimize 模块中求解<strong>多变量无约束优化</strong>问题的首选方法，<strong>局部优化方法</strong>，不要求目标函数是凸函数。采用下山单纯形方法。下山单纯形方法又称 Nelder-Mead 法，只使用目标函数值，不需要导数或二阶导数值,适合目标函数不可导或梯度难以计算的情况。但是，因为它不使用任何梯度评估，所以可能需要更长的时间才能找到最小值。</p><p>leatsq()：求解非线性最小二乘拟合问题，<strong>局部优化方法</strong>。</p><p>minimize()： SciPy.optimize 模块中求解多变量优化问题的通用方法，可以调用多种算法，支持约束优化和无约束优化，支持等式和不等式约束。</p><p>differential_evolution():<strong>全局优化</strong>方法，无导数优化方法，适用于目标函数不可导或导数难以计算的情况，鲁棒性强，直接支持约束优化。</p><p>basinhopping():<strong>全局优化</strong>方法，无导数优化方法，适用于目标函数不可导或导数难以计算的情况，鲁棒性强，不直接支持约束优化。</p></blockquote><h3 id="scipy-optimize-minimize"><a href="#scipy-optimize-minimize" class="headerlink" title="scipy.optimize.minimize"></a>scipy.optimize.minimize</h3><blockquote><p>求解函数为<strong>凸函数</strong>时，所求结果为<strong>最小值</strong>。求解函数为<strong>非凸函数</strong>时，只能求解<strong>局部最优解</strong>。</p><p>约束条件中默认为大于等于约束  。</p><p>在非线性优化问题通常对初始猜测值敏感，不同的初始猜测可能导致不同的结果。</p><p>初始猜测应满足所有约束条件，否则可能导致优化失败。</p><p>constraints: 一个字典（单个约束）或一个包含多个字典的列表/元组（多个约束）</p><p>Bounds:变量上下界的元组的列表/元组</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">c1=np.array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>]); c2=np.array([-<span class="number">8</span>,-<span class="number">2</span>,-<span class="number">3</span>,-<span class="number">1</span>,-<span class="number">2</span>])</span><br><span class="line">A=np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">6</span>],</span><br><span class="line">            [<span class="number">2</span>,<span class="number">1</span>,<span class="number">6</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>]])</span><br><span class="line">b=np.array([<span class="number">400</span>,<span class="number">800</span>,<span class="number">200</span>,<span class="number">200</span>])</span><br><span class="line">obj=<span class="keyword">lambda</span> x: -c1@x**<span class="number">2</span>+(-c2)@x</span><br><span class="line">cons=&#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;ineq&#x27;</span>,<span class="string">&#x27;fun&#x27;</span>:<span class="keyword">lambda</span> x:b-A@x&#125;</span><br><span class="line">bd=[(<span class="number">0</span>,<span class="number">99</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(A.shape[<span class="number">1</span>])]</span><br><span class="line">res=minimize(obj,np.ones(<span class="number">5</span>),constraints=cons,bounds=bd)</span><br><span class="line">res</span><br></pre></td></tr></table></figure><h3 id="scipy-optimize-differential-evolution-amp-basinhopping"><a href="#scipy-optimize-differential-evolution-amp-basinhopping" class="headerlink" title="scipy.optimize.differential_evolution &amp; basinhopping"></a>scipy.optimize.differential_evolution &amp; basinhopping</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> differential_evolution, basinhopping</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun_nonconvex</span>(<span class="params">x</span>): </span><br><span class="line">    <span class="keyword">if</span> x&lt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> ( x + <span class="number">2</span> ) ** <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ( x - <span class="number">2</span> ) ** <span class="number">2</span> + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">res_differential_evolution = differential_evolution(func=fun_nonconvex, bounds=[(-<span class="number">10</span>,<span class="number">10</span>)])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;differential_evolution()的结果为：\n&#x27;</span>, res_differential_evolution)</span><br><span class="line"></span><br><span class="line">res_basinhopping = basinhopping(func=fun_nonconvex, x0=<span class="number">0</span>, niter=<span class="number">1000</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n basinhopping()的结果为：\n&#x27;</span>, res_basinhopping)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="整数规划"><a href="#整数规划" class="headerlink" title="整数规划"></a>整数规划</h2><h3 id="线性整数规划"><a href="#线性整数规划" class="headerlink" title="线性整数规划"></a>线性整数规划</h3><blockquote><p>scipy库不能求解如背包问题的0-1规划问题，或整数规划问题，混合整数规划问题。Pulp库是一个用于线性规划（LP）、整数线性规划（ILP）和混合整数线性规划（MILP）问题的Python库，支持调用商业求解器处理大规模问题(留坑)。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pulp</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 创建一个线性规划问题，最大化总回报</span></span><br><span class="line">model = pulp.LpProblem(<span class="string">&quot;Maximize_Return&quot;</span>, pulp.LpMaximize)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 定义决策变量</span></span><br><span class="line">x_1 = pulp.LpVariable(<span class="string">&#x27;x_1&#x27;</span>, lowBound=<span class="number">0</span>, cat=<span class="string">&#x27;Integer&#x27;</span>)   </span><br><span class="line">x_2 = pulp.LpVariable(<span class="string">&#x27;x_2&#x27;</span>, lowBound=<span class="number">0</span>, cat=<span class="string">&#x27;Integer&#x27;</span>)   </span><br><span class="line">x_3 = pulp.LpVariable(<span class="string">&#x27;x_3&#x27;</span>, lowBound=<span class="number">0</span>, cat=<span class="string">&#x27;Integer&#x27;</span>)   </span><br><span class="line">x_4 = pulp.LpVariable(<span class="string">&#x27;x_4&#x27;</span>, lowBound=<span class="number">0</span>, cat=<span class="string">&#x27;Integer&#x27;</span>)   </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 建立目标函数</span></span><br><span class="line">model += <span class="number">800</span> * x_1 + <span class="number">600</span> * x_2 + <span class="number">700</span> * x_3 + <span class="number">500</span> * x_4, <span class="string">&quot;Total Return&quot;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 建立约束条件</span></span><br><span class="line">model += <span class="number">500</span> * x_1 + <span class="number">300</span> * x_2 + <span class="number">400</span> * x_3 + <span class="number">200</span> * x_4 &lt;= <span class="number">1000</span>, <span class="string">&quot;Budget Constraint&quot;</span></span><br><span class="line">model += x_3 == <span class="number">0</span>, <span class="string">&quot;Risk Constraint for Project 3&quot;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 解决问题</span></span><br><span class="line">model.solve()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看解的状态</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Status:&quot;</span>, LpStatus[prob.status])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出每个变量的最优值</span></span><br><span class="line"><span class="keyword">for</span> variable <span class="keyword">in</span> model.variables():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;variable.name&#125;</span> = <span class="subst">&#123;variable.varValue&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出最优解的目标函数值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;F3(x) =&quot;</span>, pulp.value(model.objective))</span><br></pre></td></tr></table></figure><h3 id="非线性整数规划"><a href="#非线性整数规划" class="headerlink" title="非线性整数规划"></a>非线性整数规划</h3><h4 id="Gekko"><a href="#Gekko" class="headerlink" title="Gekko"></a>Gekko</h4><blockquote><p>Gekko是一个Python库，用于解决优化问题，包括线性和非线性规划、整数规划、动态优化等。Gekko提供了易于使用的接口，并支持多种求解器，包括APOPT、BPOPT和IPOPT等。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gekko <span class="keyword">import</span> GEKKO</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Gekko模型</span></span><br><span class="line">m = GEKKO(remote=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个整数变量x和y，并设置它们的上下界</span></span><br><span class="line">x = m.Var(integer=<span class="literal">True</span>, lb=<span class="number">0</span>, ub=<span class="number">4</span>)</span><br><span class="line">y = m.Var(integer=<span class="literal">True</span>, lb=<span class="number">0</span>, ub=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义目标函数</span></span><br><span class="line">m.Obj(x**<span class="number">2</span> + y**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义约束条件</span></span><br><span class="line">m.Equation(x + y &lt;= <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求解问题</span></span><br><span class="line">m.options.SOLVER = <span class="number">1</span>  <span class="comment"># 使用 APOPT 求解器（适合混合整数非线性问题）</span></span><br><span class="line">m.solve(disp=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Results&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x: &#x27;</span> + <span class="built_in">str</span>(x.value[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y: &#x27;</span> + <span class="built_in">str</span>(y.value[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Objective: &#x27;</span> + <span class="built_in">str</span>(m.options.objfcnval))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="CVXPY"><a href="#CVXPY" class="headerlink" title="CVXPY"></a>CVXPY</h4><blockquote><p>用于解决凸优化问题（整数规划、01规划和混合规划）的Python库。对于凸函数的非线性规划，cvxpy包相对scipy,pulp更专业，功能也更强大。</p><p>部分博客说不能pip install，从实践来看有误。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cvxpy <span class="keyword">as</span> cp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">m = <span class="number">15</span></span><br><span class="line">n = <span class="number">10</span></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">s0 = np.random.randn(m)</span><br><span class="line">lamb0 = np.maximum(-s0, <span class="number">0</span>)</span><br><span class="line">s0 = np.maximum(s0, <span class="number">0</span>)</span><br><span class="line">x0 = np.random.randn(n)</span><br><span class="line">A = np.random.randn(m, n)</span><br><span class="line">b = A @ x0 + s0</span><br><span class="line">c = -A.T @ lamb0</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Define and solve the CVXPY problem.</span></span><br><span class="line">x = cp.Variable(n)</span><br><span class="line">prob = cp.Problem(cp.Minimize(c.T@x),</span><br><span class="line">                 [A @ x &lt;= b])</span><br><span class="line">prob.solve()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Print result.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nThe optimal value is&quot;</span>, prob.value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;A solution x is&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(x.value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;A dual solution is&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prob.constraints[<span class="number">0</span>].dual_value)</span><br></pre></td></tr></table></figure><h2 id="多目标规划"><a href="#多目标规划" class="headerlink" title="多目标规划"></a>多目标规划</h2><blockquote><p>多目标规划（Multi-Objective Optimization, MOO） 是一种优化方法，旨在同时优化多个目标函数。与单目标优化不同，多目标规划通常没有唯一的最优解，而是存在一组帕累托最优解（Pareto Optimal Solutions），这些解在多个目标之间实现了最佳权衡。</p></blockquote><h3 id="线性加权和法"><a href="#线性加权和法" class="headerlink" title="线性加权和法"></a>线性加权和法</h3><blockquote><p>线性加权和法对每个目标函数赋予一个权重, 从而把多目标规划转化为单目标规划。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义目标函数（加权求和）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective</span>(<span class="params">x</span>):</span><br><span class="line">    f1 = x[<span class="number">0</span>]**<span class="number">2</span> + x[<span class="number">1</span>]**<span class="number">2</span>  <span class="comment"># 目标1: 最小化 x[0]^2 + x[1]^2</span></span><br><span class="line">    f2 = (x[<span class="number">0</span>] - <span class="number">1</span>)**<span class="number">2</span> + (x[<span class="number">1</span>] - <span class="number">1</span>)**<span class="number">2</span>  <span class="comment"># 目标2: 最小化 (x[0]-1)^2 + (x[1]-1)^2</span></span><br><span class="line">    w1, w2 = <span class="number">0.5</span>, <span class="number">0.5</span>  <span class="comment"># 权重</span></span><br><span class="line">    <span class="keyword">return</span> w1 * f1 + w2 * f2  <span class="comment"># 加权求和</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义约束条件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">constraint</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x[<span class="number">0</span>] + x[<span class="number">1</span>] - <span class="number">1</span>  <span class="comment"># 约束: x[0] + x[1] = 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始值</span></span><br><span class="line">x0 = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求解</span></span><br><span class="line">solution = minimize(objective, x0, constraints=&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;eq&#x27;</span>, <span class="string">&#x27;fun&#x27;</span>: constraint&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最优解:&quot;</span>, solution.x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;目标函数值:&quot;</span>, solution.fun)</span><br></pre></td></tr></table></figure><h3 id="主要目标法-epsilon-约束方法"><a href="#主要目标法-epsilon-约束方法" class="headerlink" title="主要目标法($\epsilon$ -约束方法)"></a>主要目标法($\epsilon$ -约束方法)</h3><blockquote><p>选择一个目标作为主目标，其他目标转化为约束条件</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义主要目标函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">primary_objective</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x[<span class="number">0</span>]**<span class="number">2</span> + x[<span class="number">1</span>]**<span class="number">2</span>  <span class="comment"># 主要目标: 最小化 x[0]^2 + x[1]^2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义次要目标函数的约束条件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">secondary_constraint</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - ((x[<span class="number">0</span>] - <span class="number">1</span>)**<span class="number">2</span> + (x[<span class="number">1</span>] - <span class="number">1</span>)**<span class="number">2</span>)  <span class="comment"># 约束: (x[0]-1)^2 + (x[1]-1)^2 &lt;= 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始值</span></span><br><span class="line">x0 = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义约束条件</span></span><br><span class="line">constraints = [&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;ineq&#x27;</span>, <span class="string">&#x27;fun&#x27;</span>: secondary_constraint&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求解</span></span><br><span class="line">solution = minimize(</span><br><span class="line">    primary_objective,  <span class="comment"># 主要目标函数</span></span><br><span class="line">    x0,  <span class="comment"># 初始值</span></span><br><span class="line">    constraints=constraints  <span class="comment"># 约束条件</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最优解:&quot;</span>, solution.x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;主要目标函数值:&quot;</span>, solution.fun)</span><br></pre></td></tr></table></figure><h2 id="最大最小化规划"><a href="#最大最小化规划" class="headerlink" title="最大最小化规划"></a>最大最小化规划</h2><blockquote><p>最大最小化规划（Maximin Optimization）是一种特殊的优化问题，其核心目标是最大化最小值。在这种规划中，我们寻找一个解决方案，使得所有可能结果中的最小值尽可能大。这种方法特别适用于那些需要确保最坏情况下的最佳性能的场景，例如资源分配、公平性问题等。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义目标函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective</span>(<span class="params">x</span>):</span><br><span class="line">    t = x[<span class="number">2</span>]  <span class="comment"># 辅助变量 t</span></span><br><span class="line">    <span class="keyword">return</span> -t  <span class="comment"># 最大化 t，等价于最小化 -t</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义约束条件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">constraint1</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x[<span class="number">0</span>] + <span class="number">2</span> * x[<span class="number">1</span>] - x[<span class="number">2</span>]  <span class="comment"># f1(x) &gt;= t</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">constraint2</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">3</span> * x[<span class="number">0</span>] + x[<span class="number">1</span>] - x[<span class="number">2</span>]  <span class="comment"># f2(x) &gt;= t</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">constraint3</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">10</span> - (x[<span class="number">0</span>] + x[<span class="number">1</span>])  <span class="comment"># x1 + x2 &lt;= 10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始值</span></span><br><span class="line">x0 = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]  <span class="comment"># [x1, x2, t]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义约束条件</span></span><br><span class="line">constraints = [</span><br><span class="line">    &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;ineq&#x27;</span>, <span class="string">&#x27;fun&#x27;</span>: constraint1&#125;,  <span class="comment"># f1(x) &gt;= t</span></span><br><span class="line">    &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;ineq&#x27;</span>, <span class="string">&#x27;fun&#x27;</span>: constraint2&#125;,  <span class="comment"># f2(x) &gt;= t</span></span><br><span class="line">    &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;ineq&#x27;</span>, <span class="string">&#x27;fun&#x27;</span>: constraint3&#125;   <span class="comment"># x1 + x2 &lt;= 10</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义变量的边界</span></span><br><span class="line">bounds = [</span><br><span class="line">    (<span class="number">0</span>, <span class="literal">None</span>),  <span class="comment"># x1 &gt;= 0</span></span><br><span class="line">    (<span class="number">0</span>, <span class="literal">None</span>),  <span class="comment"># x2 &gt;= 0</span></span><br><span class="line">    (<span class="literal">None</span>, <span class="literal">None</span>)  <span class="comment"># t 无边界</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求解</span></span><br><span class="line">solution = minimize(</span><br><span class="line">    objective,  <span class="comment"># 目标函数</span></span><br><span class="line">    x0,  <span class="comment"># 初始值</span></span><br><span class="line">    method=<span class="string">&#x27;SLSQP&#x27;</span>,  <span class="comment"># 使用 SLSQP 算法</span></span><br><span class="line">    constraints=constraints,  <span class="comment"># 约束条件</span></span><br><span class="line">    bounds=bounds  <span class="comment"># 变量边界</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最优解:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x1 =&quot;</span>, solution.x[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x2 =&quot;</span>, solution.x[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t =&quot;</span>, solution.x[<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;目标函数值:&quot;</span>, -solution.fun)  <span class="comment"># 最大化 t，所以取负值</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数模 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
